# ğŸ‡§ğŸ‡© Bangla Sentiment Analysis

<div align="center">
  <img src="https://via.placeholder.com/800x200/5D44B3/ffffff?text=Bangla+Sentiment+Analysis" alt="Bangla Sentiment Analysis Banner"/>
  <p>A deep learning approach for sentiment analysis on Bangla text using Word2Vec embeddings and LSTM networks</p>
</div>

## ğŸ“Š Overview

This project implements a binary sentiment classifier for Bangla text that can classify text as either "positive" or "negative". The model uses Word2Vec for word embeddings and LSTM (Long Short-Term Memory) for sequence learning.

<div align="center">
  <img src="https://via.placeholder.com/600x300/f0f0f0/000000?text=Positive+vs+Negative+Classification" alt="Positive vs Negative Classification"/>
</div>

## ğŸ§  Model Architecture

<div align="center">
  <img src="https://via.placeholder.com/800x400/e6f7ff/000000?text=Model+Architecture" alt="Model Architecture Diagram"/>
</div>

The sentiment analysis model consists of several key components:

### Word2Vec Embeddings
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Word2Vec Configuration  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dimensions  â”‚ 100       â”‚
â”‚ Window Size â”‚ 3         â”‚
â”‚ Algorithm   â”‚ Skip-gram â”‚
â”‚ Min Count   â”‚ 3         â”‚
â”‚ Workers     â”‚ 10        â”‚
â”‚ Iterations  â”‚ 100       â”‚
â”‚ Epochs      â”‚ 40        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Neural Network Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT                             â”‚
â”‚  Bangla Text Sequence (50 tokens) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EMBEDDING LAYER                   â”‚
â”‚  Pre-trained Word2Vec (100 dim)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DROPOUT LAYER (0.5)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LSTM LAYER                        â”‚
â”‚  100 units, dropout=0.2,          â”‚
â”‚  recurrent_dropout=0.2            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DENSE LAYER                       â”‚
â”‚  1 unit, sigmoid activation       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT                            â”‚
â”‚  Binary Sentiment (0-1)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ Training Progress

<div align="center">
  <table>
    <tr>
      <td><img src="https://via.placeholder.com/400x300/e6f7ff/000000?text=Accuracy+Graph" alt="Accuracy Graph"/></td>
      <td><img src="https://via.placeholder.com/400x300/e6f7ff/000000?text=Loss+Graph" alt="Loss Graph"/></td>
    </tr>
    <tr>
      <td align="center">Model Accuracy</td>
      <td align="center">Model Loss</td>
    </tr>
  </table>
</div>

## ğŸ“ Dataset

<div align="center">
  <img src="https://via.placeholder.com/600x300/f0f0f0/000000?text=Dataset+Distribution" alt="Dataset Distribution"/>
</div>

The model is trained on a custom Bangla sentiment dataset:
- Binary classes: "positive" and "negative"
- Training/Testing split: 80%/20%
- Text sequences padded to length 50

## ğŸ“‹ Requirements

```
ğŸ“¦ Python 3.x
â”œâ”€â”€ ğŸ“¦ pandas
â”œâ”€â”€ ğŸ“¦ sklearn
â”œâ”€â”€ ğŸ“¦ gensim
â”œâ”€â”€ ğŸ“¦ keras
â”œâ”€â”€ ğŸ“¦ tensorflow
â”œâ”€â”€ ğŸ“¦ matplotlib
â””â”€â”€ ğŸ“¦ numpy
```

## ğŸš€ Usage

### Training Pipeline

<div align="center">
  <img src="https://via.placeholder.com/800x200/f0f0f0/000000?text=Training+Pipeline" alt="Training Pipeline"/>
</div>

```python
# Load and prepare data
df = pd.read_csv("your_dataset.csv", encoding="utf8", names=["bangla_text", "target"])

# Split data
df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)

# Create Word2Vec model
documents = [text.split() for text in df.bangla_text]
w2v_model = Word2Vec(size=100, window=3, min_count=3, workers=10, sg=1, iter=100)
w2v_model.build_vocab(documents)
w2v_model.train(documents, total_examples=len(documents), epochs=40)

# Prepare sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df_train.bangla_text)
x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.bangla_text), maxlen=50)
x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.bangla_text), maxlen=50)

# Train model
history = model.fit(x_train, y_train, batch_size=1024, epochs=20, validation_split=0.1)
```

### Inference

<div align="center">
  <img src="https://via.placeholder.com/600x200/f0f0f0/000000?text=Prediction+Pipeline" alt="Prediction Pipeline"/>
</div>

```python
def predict_sentiment(text):
    # Tokenize and pad the input text
    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=50)
    
    # Get prediction score
    score = model.predict([x_test])[0]
    
    # Classify based on threshold
    label = "negative" if score < 0.5 else "positive"
    
    return {"label": label, "score": float(score)}

# Example usage
result = predict_sentiment("à¦†à¦®à¦¿ à¦¤à¦¾à¦•à§‡ à¦¸à¦¬ à¦¬à¦²à¦¿ à¦¸à¦¬à¦¸à¦®à¦¯à¦¼")
print(result)
```



## ğŸ” Examples

<div align="center">
  <table>
    <tr>
      <th>Bangla Text</th>
      <th>Prediction</th>
      <th>Score</th>
    </tr>
    <tr>
      <td>à¦¸à§‡ à¦–à§à¦¬ à¦¨à¦¿à¦·à§à¦ªà¦¾à¦ª à¦®à¦¾à¦¨à§à¦· à¦¤à¦¾à¦‡ à¦¤à¦¾à¦•à§‡ à¦à¦¤ à¦­à¦¾à¦²à§‹à¦¬à¦¾à¦¸à¦¿</td>
      <td>ğŸŸ¢ Positive</td>
      <td>0.92</td>
    </tr>
    <tr>
      <td>à¦¸à§‡ à¦–à¦¾à¦°à¦¾à¦ª à¦›à§‡à¦²à§‡</td>
      <td>ğŸ”´ Negative</td>
      <td>0.12</td>
    </tr>
    <tr>
      <td>à¦¤à¦¿à¦¨à¦¿ à¦•à¦¾à¦œ à¦•à¦°à¦¤à§‡ à¦šà¦¾à¦¨ à¦¨à¦¾</td>
      <td>ğŸ”´ Negative</td>
      <td>0.31</td>
    </tr>
    <tr>
      <td>à¦¸à§‡ à¦†à¦®à¦¾à¦•à§‡ à¦–à§à¦¬ à¦ªà¦›à¦¨à§à¦¦ à¦•à¦°à§‡</td>
      <td>ğŸŸ¢ Positive</td>
      <td>0.87</td>
    </tr>
  </table>
</div>

## ğŸš€ Future Improvements

<div align="center">
  <img src="https://via.placeholder.com/800x200/f0f0f0/000000?text=Future+Development+Roadmap" alt="Future Development Roadmap"/>
</div>

- ğŸ“ˆ Experiment with different embedding dimensions
- ğŸ”„ Try different architectures (BiLSTM, Transformer-based models)
- ğŸ·ï¸ Add support for multi-class classification
- âŒ Improve handling of negation in Bangla text
- ğŸ“š Expand the dataset with more examples


---

<div align="center">
  <p>Bangla NLP Research</p>
</div>
